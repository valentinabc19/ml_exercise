{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183d88fb",
   "metadata": {},
   "source": [
    "# ***Notebook: Model Training and Evaluation***\n",
    "\n",
    "This notebook trains and evaluates multiple machine learning models to predict product conditions (\"new\" or \"used\"). The workflow includes data preprocessing, model training, and performance evaluation using metrics such as Precision, Recall, F1-Score, and Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ff507",
   "metadata": {},
   "source": [
    "***Importing Libraries***\n",
    "\n",
    "Import necessary libraries for data preprocessing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b9cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67265a34",
   "metadata": {},
   "source": [
    "***Loading the Processed Dataset***\n",
    "\n",
    "Load the preprocessed dataset created during the Exploratory Data Analysis (EDA) phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb80f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_csv('data/processed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52d93d",
   "metadata": {},
   "source": [
    "***Splitting the Dataset***\n",
    "\n",
    "Split the dataset into training and testing sets, with 80% of the data used for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a10928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop('condition', axis=1)\n",
    "y = df_model['condition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582eeff",
   "metadata": {},
   "source": [
    "### ***Data Preprocessing***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b5a01",
   "metadata": {},
   "source": [
    "***One-Hot Encoding for Categorical Features***\n",
    "\n",
    "Apply One-Hot Encoding to categorical features to convert them into numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39224a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['listing_type_id', 'buying_mode']\n",
    "preprocessor = ColumnTransformer(\n",
    "\ttransformers=[\n",
    "\t\t('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "\t],\n",
    "\tremainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "X_test_encoded = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f136ae",
   "metadata": {},
   "source": [
    "***Feature Scaling***\n",
    "\n",
    "Standardize the features to ensure all variables have the same scale, which is important for models like Logistic Regression and K-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd594e",
   "metadata": {},
   "source": [
    "### ***Training and Evaluating Models***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ecd0a2",
   "metadata": {},
   "source": [
    "***Logistic Regression***\n",
    "\n",
    "Train a Logistic Regression model and evaluate its performance using classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728ea4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.47      0.62      9283\n",
      "           1       0.67      0.96      0.79     10717\n",
      "\n",
      "    accuracy                           0.73     20000\n",
      "   macro avg       0.79      0.71      0.70     20000\n",
      "weighted avg       0.78      0.73      0.71     20000\n",
      "\n",
      "Accuracy: 0.7303\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Logistic Regression ===\")\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a3bae1",
   "metadata": {},
   "source": [
    "***Decision Tree***\n",
    "\n",
    "Train a Decision Tree model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee627c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Tree ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      9283\n",
      "           1       0.88      0.77      0.82     10717\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.82      0.82      0.82     20000\n",
      "weighted avg       0.83      0.82      0.82     20000\n",
      "\n",
      "Accuracy: 0.8181\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Decision Tree ===\")\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "model_dt.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6111dc6",
   "metadata": {},
   "source": [
    "***Random Forest***\n",
    "\n",
    "Train a Random Forest model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300edca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      9283\n",
      "           1       0.87      0.79      0.83     10717\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.82      0.83      0.82     20000\n",
      "weighted avg       0.83      0.82      0.82     20000\n",
      "\n",
      "Accuracy: 0.8223\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Random Forest ===\")\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29d01f",
   "metadata": {},
   "source": [
    "***K-Nearest Neighbors (KNN)***\n",
    "\n",
    "Train a K-Nearest Neighbors model and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d12e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== K-Nearest Neighbors (KNN) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\valen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78      9283\n",
      "           1       0.80      0.83      0.81     10717\n",
      "\n",
      "    accuracy                           0.80     20000\n",
      "   macro avg       0.80      0.79      0.80     20000\n",
      "weighted avg       0.80      0.80      0.80     20000\n",
      "\n",
      "Accuracy: 0.79665\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== K-Nearest Neighbors (KNN) ===\")\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = model_knn.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48607e35",
   "metadata": {},
   "source": [
    "### ***Comparing Model Performance***\n",
    "\n",
    "Create a summary table of metrics (Precision, Recall, F1-Score, and Accuracy) for all models to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b206f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Precision   Recall  F1-Score  Accuracy\n",
      "0  Logistic Regression   0.782686  0.73030  0.710491   0.73030\n",
      "1        Decision Tree   0.825589  0.81810  0.818157   0.81810\n",
      "2        Random Forest   0.827197  0.82230  0.822479   0.82230\n",
      "3  K-Nearest Neighbors   0.796493  0.79665  0.796346   0.79665\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"Model\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1-Score\": [],\n",
    "    \"Accuracy\": []\n",
    "}\n",
    "\n",
    "def add_metrics(model_name, y_test, y_pred):\n",
    "    metrics[\"Model\"].append(model_name)\n",
    "    metrics[\"Precision\"].append(precision_score(y_test, y_pred, average='weighted'))\n",
    "    metrics[\"Recall\"].append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    metrics[\"F1-Score\"].append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    metrics[\"Accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "add_metrics(\"Logistic Regression\", y_test, y_pred_lr)\n",
    "add_metrics(\"Decision Tree\", y_test, y_pred_dt)\n",
    "add_metrics(\"Random Forest\", y_test, y_pred_rf)\n",
    "add_metrics(\"K-Nearest Neighbors\", y_test, y_pred_knn)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725b49a",
   "metadata": {},
   "source": [
    "### ***Summary***\n",
    "\n",
    "This notebook performs the following tasks:\n",
    "\n",
    "1. Loads the preprocessed dataset.\n",
    "2. Splits the dataset into training and testing sets.\n",
    "3. Preprocesses the data using One-Hot Encoding and feature scaling.\n",
    "4. Trains and evaluates four machine learning models: ***Logistic Regression***, ***Decision Tree***, ***Random Forest***, ***K-Nearest Neighbors***\n",
    "5. Compares the performance of the models using a summary table of metrics.\n",
    "\n",
    "The results indicate that the ***Random Forest*** model achieved the best performance across all metrics, making it the most suitable model for predicting product conditions in this dataset. Further hyperparameter tuning and feature engineering could improve the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
